{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Needed Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy\n",
    "# !pip install pandas\n",
    "# !pip install tensorflow\n",
    "# !pip install keras\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install pydot\n",
    "# !pip install graphviz\n",
    "# !pip install pydotplus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\kosma\\anaconda3\\envs\\lee_gol_cnn\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Flatten, Dense, Reshape\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import seaborn as sns\n",
    "from contextlib import redirect_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "\n",
    "# Implementing the Lee algorithm for finding the shortest path in a matrix\n",
    "def lee_algorithm(matrix, start, end):\n",
    "    # Using a deque for efficient pop and append operations\n",
    "    queue = deque()\n",
    "    # Set to keep track of visited nodes\n",
    "    visited = set()\n",
    "    # Dictionary to keep track of distances from the start\n",
    "    distance = {start: 0}\n",
    "    # Dictionary to store the previous node for each visited node\n",
    "    previous = {}\n",
    "\n",
    "    # Add the start node to the queue and mark it as visited\n",
    "    queue.append(start)\n",
    "    visited.add(start)\n",
    "\n",
    "    # Continue until the queue is not empty\n",
    "    while queue:\n",
    "        # Pop the leftmost node from the queue\n",
    "        node = queue.popleft()\n",
    "\n",
    "        # Explore the neighboring nodes\n",
    "        for neighbor in get_neighbors(matrix, node):\n",
    "            # If the neighbor is not visited, update its distance and previous node, then add it to the queue\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                distance[neighbor] = distance[node] + 1\n",
    "                previous[neighbor] = node\n",
    "                queue.append(neighbor)\n",
    "\n",
    "            # If the neighbor is the end node, return the shortest path\n",
    "            if neighbor == end:\n",
    "                return get_shortest_path(previous, start, end)\n",
    "\n",
    "    # If no path is found, return None\n",
    "    return None\n",
    "\n",
    "\n",
    "# Retrieve the neighboring nodes of a given node in the matrix\n",
    "def get_neighbors(matrix, node):\n",
    "    neighbors = []\n",
    "    row, col = node\n",
    "\n",
    "    # Check the top neighbor\n",
    "    if row > 0 and matrix[row - 1][col] != 0:\n",
    "        neighbors.append((row - 1, col))\n",
    "\n",
    "    # Check the bottom neighbor\n",
    "    if row < len(matrix) - 1 and matrix[row + 1][col] != 0:\n",
    "        neighbors.append((row + 1, col))\n",
    "\n",
    "    # Check the left neighbor\n",
    "    if col > 0 and matrix[row][col - 1] != 0:\n",
    "        neighbors.append((row, col - 1))\n",
    "\n",
    "    # Check the right neighbor\n",
    "    if col < len(matrix[0]) - 1 and matrix[row][col + 1] != 0:\n",
    "        neighbors.append((row, col + 1))\n",
    "\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "# Retrieve the shortest path based on the previously stored information\n",
    "def get_shortest_path(prev, start, end):\n",
    "    path = []\n",
    "    node = end\n",
    "\n",
    "    # Trace back the path from the end node to the start node\n",
    "    while node != start:\n",
    "        path.append(node)\n",
    "        node = prev[node]\n",
    "\n",
    "    path.append(start)\n",
    "    path.reverse()\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "# Implement Conway's Game of Life rules for the given matrix\n",
    "def conways_game_of_life(matrix):\n",
    "    # Create a copy of the matrix for updating without altering the original\n",
    "    N, M = matrix.shape\n",
    "    updated_matrix = np.copy(matrix)\n",
    "\n",
    "    # Iterate through each cell in the matrix\n",
    "    for i in range(N):\n",
    "        for j in range(M):\n",
    "            # Compute the sum of the 8 neighbors\n",
    "            total = (\n",
    "                matrix[i, (j - 1) % M]\n",
    "                + matrix[i, (j + 1) % M]\n",
    "                + matrix[(i - 1) % N, j]\n",
    "                + matrix[(i + 1) % N, j]\n",
    "                + matrix[(i - 1) % N, (j - 1) % M]\n",
    "                + matrix[(i - 1) % N, (j + 1) % M]\n",
    "                + matrix[(i + 1) % N, (j - 1) % M]\n",
    "                + matrix[(i + 1) % N, (j + 1) % M]\n",
    "            )\n",
    "\n",
    "            # Apply Conway's rules for cell survival or death\n",
    "            if matrix[i, j] == 1:\n",
    "                if (total < 2) or (total > 3):\n",
    "                    updated_matrix[i, j] = 0\n",
    "            else:  # matrix[i, j] == 0\n",
    "                if total == 3:\n",
    "                    updated_matrix[i, j] = 1\n",
    "\n",
    "    return updated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Random Matrix and apply Conway's Game of Life until:\n",
    "# a) end, start exists && b) Lee algorithm returns a path\n",
    "# Return matrix, matrix_after_conways, matrix_with_path\n",
    "def generate_matrices(N, M):\n",
    "    start = (0, 0)\n",
    "    end = (N - 1, M - 1)\n",
    "\n",
    "    # Loop until the conditions are met\n",
    "    while True:\n",
    "        print(\"\\nGenerating random matrix...\")\n",
    "        matrix = np.random.randint(2, size=(N, M))\n",
    "\n",
    "        num_of_conway_iterations = 0\n",
    "        temp_matrix = matrix.copy()\n",
    "\n",
    "        # Apply Conway's Game of Life rules\n",
    "        print(\"Applying Conway's Game of Life...\")\n",
    "        while True and num_of_conway_iterations < 100:\n",
    "            # progress bar :)\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.write(\n",
    "                \"[%-100s] %d%%\"\n",
    "                % (\"=\" * num_of_conway_iterations, 1 * num_of_conway_iterations)\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "            num_of_conway_iterations += 1\n",
    "            matrix_after_conways = conways_game_of_life(temp_matrix)\n",
    "            temp_matrix = matrix_after_conways.copy()\n",
    "\n",
    "            # Check if end and start exist in matrix_after_conways\n",
    "            if (\n",
    "                matrix_after_conways[start[0]][start[1]] == 0\n",
    "                or matrix_after_conways[end[0]][end[1]] == 0\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "            # Check if the shortest path exists\n",
    "            shortest_path = lee_algorithm(\n",
    "                matrix_after_conways, start, end\n",
    "            )  # None or list of tuples (path)\n",
    "            if shortest_path:  # if path exists\n",
    "                print(\"\\nShortest path exists between %s and %s:\" % (start, end))\n",
    "                print(shortest_path)\n",
    "\n",
    "                # create final matrix with the path\n",
    "                matrix_with_path = np.zeros((N, M))\n",
    "                for i in range(len(shortest_path)):\n",
    "                    matrix_with_path[shortest_path[i][0]][shortest_path[i][1]] = 2\n",
    "\n",
    "                return (\n",
    "                    matrix,\n",
    "                    matrix_after_conways,\n",
    "                    num_of_conway_iterations,\n",
    "                    matrix_with_path,\n",
    "                )\n",
    "\n",
    "            # If the matrix is OFF, then there is no path\n",
    "            if sum(sum(matrix_after_conways)) == 0:\n",
    "                print(\n",
    "                    \"\\nCells are all zeros after %s Conway's iterations.\"\n",
    "                    % (num_of_conway_iterations)\n",
    "                )\n",
    "                print(\"Need to generate a new random matrix.\")\n",
    "                break\n",
    "\n",
    "\n",
    "# plot generated matrices\n",
    "def plot_matrices(\n",
    "    matrix, matrix_after_conways, iteration, matrix_with_path, N, M, img_name, img_path\n",
    "):\n",
    "    start = (0, 0)\n",
    "    end = (N - 1, M - 1)\n",
    "\n",
    "    # Mark start and end points on each matrix\n",
    "    matrix[start[0]][start[1]] = 2\n",
    "    matrix[end[0]][end[1]] = 2\n",
    "    matrix_after_conways[start[0]][start[1]] = 2\n",
    "    matrix_after_conways[end[0]][end[1]] = 2\n",
    "    matrix_with_path[start[0]][start[1]] = 2\n",
    "    matrix_with_path[end[0]][end[1]] = 2\n",
    "\n",
    "    # plot matrix\n",
    "    plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "    plt.rcParams[\"figure.autolayout\"] = True\n",
    "    plt.subplot(131)\n",
    "    ax = sns.heatmap(\n",
    "        matrix,\n",
    "        annot=True,\n",
    "        cmap=\"inferno\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"black\",\n",
    "        cbar=False,\n",
    "    )\n",
    "    plt.title(\"Matrix\")\n",
    "    plt.subplot(132)\n",
    "    ax = sns.heatmap(\n",
    "        matrix_after_conways,\n",
    "        annot=True,\n",
    "        cmap=\"inferno\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"black\",\n",
    "        cbar=False,\n",
    "    )\n",
    "    plt.title(\"Conways with %s iterations\" % (iteration))\n",
    "    plt.subplot(133)\n",
    "    ax = sns.heatmap(\n",
    "        matrix_with_path,\n",
    "        annot=True,\n",
    "        cmap=\"inferno\",\n",
    "        linewidths=0.5,\n",
    "        linecolor=\"black\",\n",
    "        cbar=False,\n",
    "    )\n",
    "    plt.title(\"Shortest Path\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save image locally\n",
    "    # cwd = os.getcwd()\n",
    "    plt.savefig(\"./output/\" + img_path + \"/\" + img_name)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Generate dataset of matrices\n",
    "def generate_dataset(num_of_matrices, N, M, test_name):\n",
    "    X_input = []  # initialize empty list to store the input matrices\n",
    "    X_after_conways = []  # initialize empty list to store the matrices after conways\n",
    "    y_target = (\n",
    "        []\n",
    "    )  # initialize empty list to store the output matrices (with the path on them)\n",
    "\n",
    "    # check if directories exist, if not create them\n",
    "    # cwd = os.getcwd()\n",
    "    if not os.path.exists(\"./output/\" + test_name):\n",
    "        os.mkdir(\"./output/\" + test_name)\n",
    "        os.mkdir(\"./output/\" + test_name + \"/matrices\")\n",
    "\n",
    "    for i in range(num_of_matrices):\n",
    "        print(\"\\nGenerating matrix %s...\" % (i))\n",
    "        image_name = (\n",
    "            \"matrix_\" + str(i) + \"_dimensions_\" + str(N) + \"X\" + str(M) + \".png\"\n",
    "        )\n",
    "        matrix, matrix_after_conways, iteration, matrix_with_path = generate_matrices(\n",
    "            N, M\n",
    "        )\n",
    "        plot_matrices(\n",
    "            matrix,\n",
    "            matrix_after_conways,\n",
    "            iteration,\n",
    "            matrix_with_path,\n",
    "            N,\n",
    "            M,\n",
    "            image_name,\n",
    "            test_name,\n",
    "        )\n",
    "\n",
    "        # append matrices to lists\n",
    "        X_input.append(matrix)\n",
    "        X_after_conways.append(matrix_after_conways)\n",
    "        y_target.append(matrix_with_path)\n",
    "\n",
    "    # convert final lists to numpy arrays\n",
    "    X_input = np.array(X_input)\n",
    "    X_after_conways = np.array(X_after_conways)\n",
    "    y_target = np.array(y_target)\n",
    "\n",
    "    # save numpy arrays to files\n",
    "    np.save(\"./output/\" + test_name + \"/matrices/X_input.npy\", X_input)\n",
    "    np.save(\"./output/\" + test_name + \"/matrices/X_after_conways.npy\", X_after_conways)\n",
    "    np.save(\"./output/\" + test_name + \"/matrices/y_target.npy\", y_target)\n",
    "\n",
    "    print(\"\\n\\nMatrices saved to files successfully!\")\n",
    "\n",
    "\n",
    "# Function to remove duplicates from dataset\n",
    "def remove_duplicates(matrix, matrix_after_conways, matrix_with_path):\n",
    "    # Create copies of matrices\n",
    "    matrix_clean = np.copy(matrix)\n",
    "    matrix_after_conways_clean = np.copy(matrix_after_conways)\n",
    "    matrix_with_path_clean = np.copy(matrix_with_path)\n",
    "\n",
    "    while True:\n",
    "        # List to store the indexes of duplicates\n",
    "        list_of_duplicates_indexes = []\n",
    "\n",
    "        # Iterate through all matrices and remove duplicates\n",
    "        for i in range(matrix_clean.shape[0]):\n",
    "            for j in range(i + 1, matrix_clean.shape[0]):\n",
    "                # Check if the index is out of the range of the matrix\n",
    "                if j >= matrix_clean.shape[0]:\n",
    "                    break\n",
    "\n",
    "                # Check if duplicates are found\n",
    "                if np.all(\n",
    "                    matrix_after_conways_clean[i] == matrix_after_conways_clean[j]\n",
    "                ):\n",
    "                    # Add the indexes of duplicates to the list\n",
    "                    list_of_duplicates_indexes.append(j)\n",
    "\n",
    "                    # Remove duplicates\n",
    "                    matrix_clean = np.delete(matrix_clean, j, axis=0)\n",
    "                    matrix_after_conways_clean = np.delete(\n",
    "                        matrix_after_conways_clean, j, axis=0\n",
    "                    )\n",
    "                    matrix_with_path_clean = np.delete(\n",
    "                        matrix_with_path_clean, j, axis=0\n",
    "                    )\n",
    "\n",
    "        # If no duplicates are found, exit the loop\n",
    "        if len(list_of_duplicates_indexes) == 0:\n",
    "            break\n",
    "\n",
    "    # Return the matrices and the list of duplicate indexes\n",
    "    return matrix_clean, matrix_after_conways_clean, matrix_with_path_clean\n",
    "\n",
    "\n",
    "# Load datasets from the datasets directory\n",
    "def load_datasets(name, index=1):\n",
    "    # Load the first dataset\n",
    "    dataset_name = name + \"_\" + str(index)\n",
    "    matrix = np.load(\"./datasets/\" + dataset_name + \"/matrices/X_input.npy\")\n",
    "    matrix_after_conways = np.load(\n",
    "        \"./datasets/\" + dataset_name + \"/matrices/X_after_conways.npy\"\n",
    "    )\n",
    "    matrix_with_path = np.load(\"./datasets/\" + dataset_name + \"/matrices/y_target.npy\")\n",
    "\n",
    "    # # Print the shapes of the matrices\n",
    "    # print(\"matrix shape: \", matrix.shape)\n",
    "    # print(\"matrix_after_conways shape: \", matrix_after_conways.shape)\n",
    "    # print(\"matrix_with_path shape: \", matrix_with_path.shape)\n",
    "\n",
    "    # Load all datasets from the output directory that start with \"dataset_\"\n",
    "    with os.scandir(\"./datasets\") as entries:\n",
    "        for entry in entries:\n",
    "            if (\n",
    "                entry.is_dir()\n",
    "                and entry.name.startswith(\"dataset_\")\n",
    "                and entry.name != dataset_name\n",
    "            ):\n",
    "                matrix = np.concatenate(\n",
    "                    (\n",
    "                        matrix,\n",
    "                        np.load(\"./datasets/\" + entry.name + \"/matrices/X_input.npy\"),\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                matrix_after_conways = np.concatenate(\n",
    "                    (\n",
    "                        matrix_after_conways,\n",
    "                        np.load(\n",
    "                            \"./datasets/\" + entry.name + \"/matrices/X_after_conways.npy\"\n",
    "                        ),\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "                matrix_with_path = np.concatenate(\n",
    "                    (\n",
    "                        matrix_with_path,\n",
    "                        np.load(\"./datasets/\" + entry.name + \"/matrices/y_target.npy\"),\n",
    "                    ),\n",
    "                    axis=0,\n",
    "                )\n",
    "\n",
    "    # # Print the shapes of the matrices\n",
    "    # print(\"matrix shape: \", matrix.shape)\n",
    "    # print(\"matrix_after_conways shape: \", matrix_after_conways.shape)\n",
    "    # print(\"matrix_with_path shape: \", matrix_with_path.shape)\n",
    "\n",
    "    # Remove duplicates from the matrices\n",
    "    (\n",
    "        matrix_clean,\n",
    "        matrix_after_conways_clean,\n",
    "        matrix_with_path_clean,\n",
    "    ) = remove_duplicates(matrix, matrix_after_conways, matrix_with_path)\n",
    "\n",
    "    # # Print the shapes of the matrices after removing duplicates\n",
    "    # print(\"matrix_clean shape: \", matrix_clean.shape)\n",
    "    # print(\"matrix_after_conways_clean shape: \", matrix_after_conways_clean.shape)\n",
    "    # print(\"matrix_with_path_clean shape: \", matrix_with_path_clean.shape)\n",
    "\n",
    "    # # Save the matrices\n",
    "    # np.save(\"./output/X_input_clean.npy\", matrix_clean)\n",
    "    # np.save(\"./output/X_after_conways_clean.npy\", matrix_after_conways_clean)\n",
    "    # np.save(\"./output/y_target_clean.npy\", matrix_with_path_clean)\n",
    "\n",
    "    # print(\"\\n\\nMatrices saved to files successfully!\")\n",
    "\n",
    "    return matrix_clean, matrix_after_conways_clean, matrix_with_path_clean\n",
    "\n",
    "\n",
    "# Generate a Random Matrix and apply Conway's Game of Life\n",
    "# until: a) end, start exists && b) Lee algorithm DOESN'T return a path\n",
    "# Return matrix_without, matrix_after_conways_without, matrix_without_path\n",
    "def generate_matrices_without_path(N, M):\n",
    "    start = (0, 0)\n",
    "    end = (N - 1, M - 1)\n",
    "\n",
    "    while True:\n",
    "        print(\"\\nGenerating a random matrix...\")\n",
    "        matrix = np.random.randint(2, size=(N, M))\n",
    "\n",
    "        num_of_conway_iterations = 0\n",
    "        temp_matrix = matrix.copy()\n",
    "\n",
    "        print(\"Applying Conway's Game of Life...\")\n",
    "        while True and num_of_conway_iterations < 100:\n",
    "            # Progress bar :)\n",
    "            sys.stdout.write(\"\\r\")\n",
    "            sys.stdout.write(\n",
    "                \"[%-100s] %d%%\"\n",
    "                % (\"=\" * num_of_conway_iterations, 1 * num_of_conway_iterations)\n",
    "            )\n",
    "            sys.stdout.flush()\n",
    "            time.sleep(0.05)\n",
    "\n",
    "            num_of_conway_iterations += 1\n",
    "            matrix_after_conways = conways_game_of_life(temp_matrix)\n",
    "\n",
    "            temp_matrix = matrix_after_conways.copy()\n",
    "\n",
    "            # Check if end and start exist in matrix_after_conways\n",
    "            if (\n",
    "                matrix_after_conways[start[0]][start[1]] == 0\n",
    "                or matrix_after_conways[end[0]][end[1]] == 0\n",
    "            ):\n",
    "                # print(\"Start or end does not exist in matrix. Need to generate a new matrix.\")\n",
    "                continue\n",
    "\n",
    "            shortest_path = lee_algorithm(\n",
    "                matrix_after_conways, start, end\n",
    "            )  # None or list of tuples (path)\n",
    "\n",
    "            # If path DOESN'T exist\n",
    "            if not shortest_path:\n",
    "                print(\"\\nShortest path doesn't exist between %s and %s:\" % (start, end))\n",
    "\n",
    "                # Create the final matrix without a path as a copy of matrix_after_conways\n",
    "                matrix_without_path = matrix_after_conways.copy()\n",
    "\n",
    "                return (\n",
    "                    matrix,\n",
    "                    matrix_after_conways,\n",
    "                    num_of_conway_iterations,\n",
    "                    matrix_without_path,\n",
    "                )\n",
    "\n",
    "            # If the matrix is OFF, then there is no path\n",
    "            if sum(sum(matrix_after_conways)) == 0:\n",
    "                print(\n",
    "                    \"\\nCells are all zeros after %s conways iteration.\"\n",
    "                    % (num_of_conway_iterations)\n",
    "                )\n",
    "                print(\"Need to generate a new random matrix.\")\n",
    "                break\n",
    "\n",
    "\n",
    "# Generate a dataset of matrices without a path\n",
    "def generate_dataset_without_path(num_of_matrices, N, M, test_name):\n",
    "    X_input = []  # initialize an empty list to store the input matrices\n",
    "    X_after_conways = []  # initialize an empty list to store the matrices after conways\n",
    "    y_target = (\n",
    "        []\n",
    "    )  # initialize an empty list to store the output matrices (with the path on them)\n",
    "\n",
    "    for i in range(num_of_matrices):\n",
    "        print(\"\\nGenerating matrix without a path %s...\" % (i))\n",
    "        image_name = (\n",
    "            \"matrix_without_path_\"\n",
    "            + str(i)\n",
    "            + \"_dimensions_\"\n",
    "            + str(N)\n",
    "            + \"X\"\n",
    "            + str(M)\n",
    "            + \".png\"\n",
    "        )\n",
    "        (\n",
    "            matrix,\n",
    "            matrix_after_conways,\n",
    "            iteration,\n",
    "            matrix_with_path,\n",
    "        ) = generate_matrices_without_path(N, M)\n",
    "        plot_matrices(\n",
    "            matrix,\n",
    "            matrix_after_conways,\n",
    "            iteration,\n",
    "            matrix_with_path,\n",
    "            N,\n",
    "            M,\n",
    "            image_name,\n",
    "            test_name,\n",
    "        )\n",
    "\n",
    "        # append matrices to lists\n",
    "        X_input.append(matrix)\n",
    "        X_after_conways.append(matrix_after_conways)\n",
    "        y_target.append(matrix_with_path)\n",
    "\n",
    "    # convert final lists to numpy arrays\n",
    "    X_input = np.array(X_input)\n",
    "    X_after_conways = np.array(X_after_conways)\n",
    "    y_target = np.array(y_target)\n",
    "\n",
    "    # save numpy arrays to files\n",
    "    np.save(\"./datasets/\" + test_name + \"/matrices/X_input_without.npy\", X_input)\n",
    "    np.save(\n",
    "        \"./datasets/\" + test_name + \"/matrices/X_after_conways_without.npy\",\n",
    "        X_after_conways,\n",
    "    )\n",
    "    np.save(\"./datasets/\" + test_name + \"/matrices/y_target_without.npy\", y_target)\n",
    "\n",
    "    print(\"\\n\\nMatrices saved to files successfully!\")\n",
    "\n",
    "    return X_input, X_after_conways, y_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create 10 datasets for training and testing\n",
    "## Dimensions of matrices: 5x5\n",
    "## Number of matrices: 100\n",
    "## Name of dataset: dataset_1, dataset_2, ..., dataset_10\n",
    "def create_10_datasets():\n",
    "    for i in range(10):\n",
    "        test_name = \"dataset_\" + str(i + 1)\n",
    "        num_of_matrices = 100\n",
    "        matrix_rows = 5\n",
    "        matrix_cols = 5\n",
    "        generate_dataset(num_of_matrices, matrix_rows, matrix_cols, test_name)\n",
    "\n",
    "    print(\"10 datasets created successfully!\")\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "# create_10_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 62AA-4F6D\n",
      "\n",
      " Directory of c:\\Users\\kosma\\Desktop\\GitHub\\lee-gol-cnn\n",
      "\n",
      "07-Dec-23  19:43    <DIR>          .\n",
      "07-Dec-23  19:43    <DIR>          ..\n",
      "07-Dec-23  19:01    <DIR>          datasets\n",
      "21-Oct-23  19:11             1,095 LICENSE\n",
      "07-Dec-23  19:43    <DIR>          output\n",
      "07-Dec-23  19:18             1,383 README.md\n",
      "07-Dec-23  00:46    <DIR>          src\n",
      "               2 File(s)          2,478 bytes\n",
      "               5 Dir(s)  380,750,041,088 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part loads 10 folders of datasets (1000 arrays in total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix shape:  (100, 5, 5)\n",
      "matrix_after_conways shape:  (100, 5, 5)\n",
      "matrix_with_path shape:  (100, 5, 5)\n",
      "matrix shape:  (200, 5, 5)\n",
      "matrix_after_conways shape:  (200, 5, 5)\n",
      "matrix_with_path shape:  (200, 5, 5)\n",
      "matrix shape:  (300, 5, 5)\n",
      "matrix_after_conways shape:  (300, 5, 5)\n",
      "matrix_with_path shape:  (300, 5, 5)\n",
      "matrix shape:  (400, 5, 5)\n",
      "matrix_after_conways shape:  (400, 5, 5)\n",
      "matrix_with_path shape:  (400, 5, 5)\n",
      "matrix shape:  (500, 5, 5)\n",
      "matrix_after_conways shape:  (500, 5, 5)\n",
      "matrix_with_path shape:  (500, 5, 5)\n",
      "matrix shape:  (600, 5, 5)\n",
      "matrix_after_conways shape:  (600, 5, 5)\n",
      "matrix_with_path shape:  (600, 5, 5)\n",
      "matrix shape:  (700, 5, 5)\n",
      "matrix_after_conways shape:  (700, 5, 5)\n",
      "matrix_with_path shape:  (700, 5, 5)\n",
      "matrix shape:  (800, 5, 5)\n",
      "matrix_after_conways shape:  (800, 5, 5)\n",
      "matrix_with_path shape:  (800, 5, 5)\n",
      "matrix shape:  (900, 5, 5)\n",
      "matrix_after_conways shape:  (900, 5, 5)\n",
      "matrix_with_path shape:  (900, 5, 5)\n",
      "matrix shape:  (1000, 5, 5)\n",
      "matrix_after_conways shape:  (1000, 5, 5)\n",
      "matrix_with_path shape:  (1000, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# # load 10 folders of datasets\n",
    "\n",
    "matrix, matrix_after_conways, matrix_with_path = load_datasets(\"dataset\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "print(matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Conv2D,\n",
    "    Flatten,\n",
    "    Dense,\n",
    "    Reshape,\n",
    "    Dropout,\n",
    "    MaxPooling2D,\n",
    "    BatchNormalization,\n",
    ")\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "\n",
    "# Global Model Parameters\n",
    "OUTPUT_PATH = \"output/\"\n",
    "CURRENT_RUN = \"run_\"\n",
    "MODEL_NAME = \"CNN_model\"\n",
    "ACTIVATION_FUNCTION = \"sigmoid\"\n",
    "LOSS_FUNCTION = \"mean_squared_error\"\n",
    "OPTIMIZER = \"adam\"\n",
    "METRICS = [\"accuracy\"]\n",
    "EPOCHS = 20\n",
    "PATIENCE = 10\n",
    "\n",
    "NUM_OF_MATRICES = 100\n",
    "MATRIX_ROWS = 5\n",
    "MATRIX_COLS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the last run of the model\n",
    "def find_last_run():\n",
    "    # Find the last run of the model\n",
    "    last_run = 0\n",
    "    for entry in os.scandir(OUTPUT_PATH):\n",
    "        if entry.is_dir() and entry.name.startswith(CURRENT_RUN):\n",
    "            last_run = max(last_run, int(entry.name.split(\"_\")[1]))\n",
    "\n",
    "    return last_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset (shuffle and split into training and test sets (80%:20%))\n",
    "def preprocess(matrix, matrix_after_conways, matrix_with_path):\n",
    "    # Shuffle the matrices\n",
    "    def custom_random():\n",
    "        # Define your custom random function logic here\n",
    "        return random.random() * 0.5\n",
    "\n",
    "    random_order = [i for i in range(len(matrix))]\n",
    "    # random.shuffle(random_order, custom_random)\n",
    "\n",
    "    # Shuffle the matrices according to the randomly created list\n",
    "    matrix[:] = matrix[random_order]\n",
    "    matrix_after_conways[:] = matrix_after_conways[random_order]\n",
    "    matrix_with_path[:] = matrix_with_path[random_order]\n",
    "\n",
    "    # Split the dataset into a training set and test set (80%:20%)\n",
    "    split_ratio = 0.8\n",
    "\n",
    "    # Training set\n",
    "    matrix_train = matrix[: int(len(matrix) * split_ratio)]\n",
    "    matrix_after_conways_train = matrix_after_conways[\n",
    "        : int(len(matrix_after_conways) * split_ratio)\n",
    "    ]\n",
    "    matrix_with_path_train = matrix_with_path[\n",
    "        : int(len(matrix_with_path) * split_ratio)\n",
    "    ]\n",
    "\n",
    "    # Test set\n",
    "    matrix_test = matrix[int(len(matrix) * split_ratio) :]\n",
    "    matrix_after_conways_test = matrix_after_conways[\n",
    "        int(len(matrix_after_conways) * split_ratio) :\n",
    "    ]\n",
    "    matrix_with_path_test = matrix_with_path[int(len(matrix_with_path) * split_ratio) :]\n",
    "\n",
    "    return (\n",
    "        matrix_train,\n",
    "        matrix_after_conways_train,\n",
    "        matrix_with_path_train,\n",
    "        matrix_test,\n",
    "        matrix_after_conways_test,\n",
    "        matrix_with_path_test,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(\n",
    "        self,\n",
    "        matrix_after_conways_train,\n",
    "        matrix_with_path_train,\n",
    "        matrix_after_conways_test,\n",
    "        matrix_with_path_test,\n",
    "        model=None,\n",
    "    ):\n",
    "        self.matrix_after_conways_train = matrix_after_conways_train\n",
    "        self.matrix_with_path_train = matrix_with_path_train\n",
    "        self.matrix_after_conways_test = matrix_after_conways_test\n",
    "        self.matrix_with_path_test = matrix_with_path_test\n",
    "        self.model = model\n",
    "\n",
    "    def build(self):\n",
    "        # Initialize the model\n",
    "        self.model = Sequential(name=MODEL_NAME)\n",
    "\n",
    "        # CNN layer for 2D input\n",
    "        self.model.add(\n",
    "            Conv2D(\n",
    "                32, (3, 3), activation=\"relu\", input_shape=(MATRIX_ROWS, MATRIX_COLS, 1)\n",
    "            )\n",
    "        )\n",
    "        # Flatten layer for the tensor to 1D vector\n",
    "        self.model.add(Flatten())\n",
    "\n",
    "        # Dense layer\n",
    "        self.model.add(Dense(25, activation=ACTIVATION_FUNCTION))\n",
    "\n",
    "        # Need to reshape the tensor to 2D matrix\n",
    "        self.model.add(Reshape((MATRIX_ROWS, MATRIX_COLS, 1)))\n",
    "\n",
    "        # Compile the model\n",
    "        self.model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "\n",
    "        # Callback to prevent overfitting\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=PATIENCE)\n",
    "\n",
    "        # Print the model summary\n",
    "        self.model.summary()\n",
    "\n",
    "        # Fit the model\n",
    "        self.model.fit(\n",
    "            self.matrix_after_conways_train,\n",
    "            self.matrix_with_path_train,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(\n",
    "                self.matrix_after_conways_test,\n",
    "                self.matrix_with_path_test,\n",
    "            ),\n",
    "            callbacks=[callback],\n",
    "        )\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def build_v2(self):\n",
    "        # Initialize the model\n",
    "        self.model = Sequential(name=MODEL_NAME)\n",
    "\n",
    "        # CNN layer for 2D input\n",
    "        self.model.add(\n",
    "            Conv2D(\n",
    "                32,\n",
    "                (3, 3),\n",
    "                activation=\"relu\",\n",
    "                input_shape=(MATRIX_ROWS, MATRIX_COLS, 1),\n",
    "                padding=\"same\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Extra layers for better accuracy\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(\n",
    "            Conv2D(32, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")\n",
    "        )\n",
    "        self.model.add(BatchNormalization())\n",
    "        # self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        self.model.add(\n",
    "            Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")\n",
    "        )\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(\n",
    "            Conv2D(64, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")\n",
    "        )\n",
    "        self.model.add(BatchNormalization())\n",
    "        # self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        self.model.add(\n",
    "            Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")\n",
    "        )\n",
    "        self.model.add(BatchNormalization())\n",
    "        self.model.add(\n",
    "            Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\")\n",
    "        )\n",
    "        self.model.add(BatchNormalization())\n",
    "        # self.model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        # Flatten layer for the tensor to 1D vector\n",
    "        self.model.add(Flatten())\n",
    "\n",
    "        # Dense layer\n",
    "        self.model.add(Dense(25, activation=ACTIVATION_FUNCTION))\n",
    "\n",
    "        # Need to reshape the tensor to 2D matrix\n",
    "        self.model.add(Reshape((MATRIX_ROWS, MATRIX_COLS, 1)))\n",
    "\n",
    "        # Compile the model\n",
    "        self.model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=METRICS)\n",
    "\n",
    "        # Callback to prevent overfitting\n",
    "        callback = tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=PATIENCE)\n",
    "\n",
    "        # Print the model summary\n",
    "        self.model.summary()\n",
    "\n",
    "        # Fit the model\n",
    "        self.model.fit(\n",
    "            self.matrix_after_conways_train,\n",
    "            self.matrix_with_path_train,\n",
    "            epochs=EPOCHS,\n",
    "            validation_data=(\n",
    "                self.matrix_after_conways_test,\n",
    "                self.matrix_with_path_test,\n",
    "            ),\n",
    "            callbacks=[callback],\n",
    "        )\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def save(self):\n",
    "        output_path = OUTPUT_PATH + CURRENT_RUN + str(find_last_run() + 1) + \"/\"\n",
    "\n",
    "        # Create the output folder\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "\n",
    "        # Save the summary of the model\n",
    "        with open(output_path + MODEL_NAME + \"_summary.txt\", \"w\") as f:\n",
    "            with redirect_stdout(f):\n",
    "                self.model.summary()\n",
    "\n",
    "        # Save the model architecture\n",
    "        model_json = self.model.to_json()\n",
    "        with open(output_path + MODEL_NAME + \".json\", \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "\n",
    "        # Save the model parameters\n",
    "        with open(output_path + MODEL_NAME + \"_parameters.txt\", \"w\") as f:\n",
    "            f.write(\"Activation function: \" + ACTIVATION_FUNCTION + \"\\n\")\n",
    "            f.write(\"Loss function: \" + LOSS_FUNCTION + \"\\n\")\n",
    "            f.write(\"Optimizer: \" + OPTIMIZER + \"\\n\")\n",
    "            f.write(\"Metrics: \" + str(METRICS) + \"\\n\")\n",
    "            f.write(\"Epochs: \" + str(EPOCHS) + \"\\n\")\n",
    "            f.write(\"Patience: \" + str(PATIENCE) + \"\\n\")\n",
    "\n",
    "        # Save the model\n",
    "        self.model.save(output_path + MODEL_NAME + \".h5\")\n",
    "\n",
    "    def plot(self):\n",
    "        output_path = OUTPUT_PATH + CURRENT_RUN + str(find_last_run()) + \"/\"\n",
    "\n",
    "        # Plot the model\n",
    "        tf.keras.utils.plot_model(\n",
    "            self.model,\n",
    "            to_file=output_path + MODEL_NAME + \".png\",\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "\n",
    "        # Plot the training and validation accuracy and loss at each epoch\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.model.history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "        plt.plot(\n",
    "            self.model.history.history[\"val_accuracy\"], label=\"Validation Accuracy\"\n",
    "        )\n",
    "        plt.title(\"Training and Validation Accuracy\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.model.history.history[\"loss\"], label=\"Training Loss\")\n",
    "        plt.plot(self.model.history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "        plt.title(\"Training and Validation Loss\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.savefig(output_path + MODEL_NAME + \"_plot.png\")\n",
    "        plt.close()\n",
    "\n",
    "    # Plot extra plots that show the matrices before and after Conways,\n",
    "    # the prediction and the difference between the prediction and the matrix with path\n",
    "    def plot_extra(self):\n",
    "        output_path = OUTPUT_PATH + CURRENT_RUN + str(find_last_run()) + \"/\"\n",
    "        for i in range(5):\n",
    "            manager = plt.get_current_fig_manager()\n",
    "            manager.full_screen_toggle()\n",
    "\n",
    "            plt.subplot(151)\n",
    "            ax = sns.heatmap(\n",
    "                self.matrix_after_conways_test[i, :, :],\n",
    "                annot=True,\n",
    "                cmap=\"inferno\",\n",
    "                linewidths=0.5,\n",
    "                linecolor=\"black\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(\"Matrix after Conways\")\n",
    "            plt.subplot(152)\n",
    "            ax = sns.heatmap(\n",
    "                self.matrix_with_path_test[i, :, :],\n",
    "                annot=True,\n",
    "                cmap=\"inferno\",\n",
    "                linewidths=0.5,\n",
    "                linecolor=\"black\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(\"Matrix with path\")\n",
    "\n",
    "            plt.subplot(153)\n",
    "            ax = sns.heatmap(\n",
    "                np.around(\n",
    "                    np.abs(\n",
    "                        self.model.predict(\n",
    "                            self.matrix_after_conways_test[i, :, :].reshape(1, 5, 5, 1)\n",
    "                        ).reshape(5, 5)\n",
    "                    ),\n",
    "                    decimals=2,\n",
    "                ),\n",
    "                annot=True,\n",
    "                cmap=\"inferno\",\n",
    "                linewidths=0.5,\n",
    "                linecolor=\"black\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(\"Prediction\")\n",
    "\n",
    "            plt.subplot(154)\n",
    "            ax = sns.heatmap(\n",
    "                np.around(\n",
    "                    np.abs(\n",
    "                        self.matrix_with_path_test[i, :, :]\n",
    "                        - self.model.predict(\n",
    "                            self.matrix_after_conways_test[i, :, :].reshape(1, 5, 5, 1)\n",
    "                        ).reshape(5, 5)\n",
    "                        * 2\n",
    "                    ),\n",
    "                    decimals=2,\n",
    "                ),\n",
    "                annot=True,\n",
    "                cmap=\"inferno\",\n",
    "                linewidths=0.5,\n",
    "                linecolor=\"black\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(\"Difference\")\n",
    "\n",
    "            plt.subplot(155)\n",
    "            ax = sns.heatmap(\n",
    "                np.around(\n",
    "                    np.abs(\n",
    "                        self.matrix_with_path_test[i, :, :]\n",
    "                        - self.model.predict(\n",
    "                            self.matrix_after_conways_test[i, :, :].reshape(1, 5, 5, 1)\n",
    "                        ).reshape(5, 5)\n",
    "                        * 2\n",
    "                    ),\n",
    "                    decimals=2,\n",
    "                )\n",
    "                > 1.0,\n",
    "                annot=True,\n",
    "                cmap=\"inferno\",\n",
    "                linewidths=0.5,\n",
    "                linecolor=\"black\",\n",
    "                cbar=False,\n",
    "            )\n",
    "            plt.title(\"Difference > 1.0\")\n",
    "\n",
    "            fig = plt.gcf()\n",
    "            fig.set_size_inches((22, 11), forward=False)\n",
    "            plt.savefig(\n",
    "                output_path + MODEL_NAME + \"_plot_extra_\" + str(i) + \".png\", dpi=500\n",
    "            )\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kosma\\Desktop\\GitHub\\lee-gol-cnn\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load 10 folders of datasets\n",
    "\n",
    "# matrix = np.zeros((0, 5, 5))\n",
    "# matrix_after_conways = np.zeros((0, 5, 5))\n",
    "# matrix_with_path = np.zeros((0, 5, 5))\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "\n",
    "#     temp_matrix, temp_matrix_after_conways, temp_matrix_with_path = load_datasets(\"datasets/dataset\", i + 1)\n",
    "\n",
    "#     matrix = np.concatenate((matrix, temp_matrix), axis=0)\n",
    "\n",
    "#     matrix_after_conways = np.concatenate((matrix_after_conways, temp_matrix_after_conways), axis=0)\n",
    "#     matrix_with_path = np.concatenate((matrix_with_path, temp_matrix_with_path), axis=0)\n",
    "\n",
    "# print(matrix.shape)\n",
    "\n",
    "# print(matrix_after_conways.shape)\n",
    "# print(matrix_with_path.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # load datasets\n",
    "    matrix, matrix_after_conways, matrix_with_path = load_datasets(\"dataset\", 1)\n",
    "\n",
    "    # print matrices shapes\n",
    "    print(\"\\n\\nDataset before preprocessing:\")\n",
    "    print(\" -Matrix shape: \", matrix.shape)\n",
    "    print(\" -Matrix after conways shape: \", matrix_after_conways.shape)\n",
    "    print(\" -Matrix with path shape: \", matrix_with_path.shape)\n",
    "\n",
    "    # preprocess dataset\n",
    "    (\n",
    "        matrix_train,\n",
    "        matrix_after_conways_train,\n",
    "        matrix_with_path_train,\n",
    "        matrix_test,\n",
    "        matrix_after_conways_test,\n",
    "        matrix_with_path_test,\n",
    "    ) = preprocess(matrix, matrix_after_conways, matrix_with_path)\n",
    "\n",
    "    # print matrices shapes\n",
    "    print(\"\\n\\nDataset after preprocessing:\")\n",
    "    print(\" -Matrix train shape: \", matrix_train.shape)\n",
    "    print(\" -Matrix after conways train shape: \", matrix_after_conways_train.shape)\n",
    "    print(\" -Matrix with path train shape: \", matrix_with_path_train.shape)\n",
    "    print(\" -Matrix test shape: \", matrix_test.shape)\n",
    "    print(\" -Matrix after conways test shape: \", matrix_after_conways_test.shape)\n",
    "    print(\" -Matrix with path test shape: \", matrix_with_path_test.shape)\n",
    "\n",
    "    # Create the CNN model\n",
    "    cnn = CNN(\n",
    "        matrix_after_conways_train,\n",
    "        matrix_with_path_train,\n",
    "        matrix_after_conways_test,\n",
    "        matrix_with_path_test,\n",
    "    )\n",
    "\n",
    "    # Build the CNN model\n",
    "    cnn.build()\n",
    "\n",
    "    # Save the CNN model\n",
    "    cnn.save()\n",
    "\n",
    "    # Plot the CNN model\n",
    "    cnn.plot()\n",
    "\n",
    "    # Plot extra useful plots\n",
    "    cnn.plot_extra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset before preprocessing:\n",
      " -Matrix shape:  (1410, 5, 5)\n",
      " -Matrix after conways shape:  (1410, 5, 5)\n",
      " -Matrix with path shape:  (1410, 5, 5)\n",
      "\n",
      "\n",
      "Dataset after preprocessing:\n",
      " -Matrix train shape:  (1128, 5, 5)\n",
      " -Matrix after conways train shape:  (1128, 5, 5)\n",
      " -Matrix with path train shape:  (1128, 5, 5)\n",
      " -Matrix test shape:  (282, 5, 5)\n",
      " -Matrix after conways test shape:  (282, 5, 5)\n",
      " -Matrix with path test shape:  (282, 5, 5)\n",
      "Model: \"CNN_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 3, 3, 32)          320       \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 288)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 25)                7225      \n",
      "                                                                 \n",
      " reshape_3 (Reshape)         (None, 5, 5, 1)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7545 (29.47 KB)\n",
      "Trainable params: 7545 (29.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "36/36 [==============================] - 1s 9ms/step - loss: 0.8798 - accuracy: 0.3172 - val_loss: 0.7859 - val_accuracy: 0.3014\n",
      "Epoch 2/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.7400 - accuracy: 0.3338 - val_loss: 0.7123 - val_accuracy: 0.3712\n",
      "Epoch 3/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.3994 - val_loss: 0.6501 - val_accuracy: 0.4153\n",
      "Epoch 4/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.6249 - accuracy: 0.4406 - val_loss: 0.6019 - val_accuracy: 0.4611\n",
      "Epoch 5/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5834 - accuracy: 0.4736 - val_loss: 0.5690 - val_accuracy: 0.4857\n",
      "Epoch 6/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5552 - accuracy: 0.4942 - val_loss: 0.5431 - val_accuracy: 0.5037\n",
      "Epoch 7/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5349 - accuracy: 0.5102 - val_loss: 0.5251 - val_accuracy: 0.5162\n",
      "Epoch 8/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.5212 - val_loss: 0.5111 - val_accuracy: 0.5301\n",
      "Epoch 9/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.5302 - val_loss: 0.5005 - val_accuracy: 0.5319\n",
      "Epoch 10/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.5357 - val_loss: 0.4911 - val_accuracy: 0.5420\n",
      "Epoch 11/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.5419 - val_loss: 0.4840 - val_accuracy: 0.5516\n",
      "Epoch 12/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.5466 - val_loss: 0.4749 - val_accuracy: 0.5519\n",
      "Epoch 13/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.5520 - val_loss: 0.4661 - val_accuracy: 0.5650\n",
      "Epoch 14/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.5626 - val_loss: 0.4594 - val_accuracy: 0.5705\n",
      "Epoch 15/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.5680 - val_loss: 0.4528 - val_accuracy: 0.5698\n",
      "Epoch 16/20\n",
      "36/36 [==============================] - 0s 6ms/step - loss: 0.4528 - accuracy: 0.5704 - val_loss: 0.4481 - val_accuracy: 0.5765\n",
      "Epoch 17/20\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.5728 - val_loss: 0.4444 - val_accuracy: 0.5791\n",
      "Epoch 18/20\n",
      "36/36 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.5771 - val_loss: 0.4408 - val_accuracy: 0.5820\n",
      "Epoch 19/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.5794 - val_loss: 0.4377 - val_accuracy: 0.5857\n",
      "Epoch 20/20\n",
      "36/36 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.5812 - val_loss: 0.4353 - val_accuracy: 0.5858\n",
      "1/1 [==============================] - 0s 99ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset before preprocessing:\n",
      " -Matrix shape:  (608, 5, 5)\n",
      " -Matrix after conways shape:  (608, 5, 5)\n",
      " -Matrix with path shape:  (608, 5, 5)\n",
      "\n",
      "\n",
      "Dataset after preprocessing:\n",
      " -Matrix train shape:  (486, 5, 5)\n",
      " -Matrix after conways train shape:  (486, 5, 5)\n",
      " -Matrix with path train shape:  (486, 5, 5)\n",
      " -Matrix test shape:  (122, 5, 5)\n",
      " -Matrix after conways test shape:  (122, 5, 5)\n",
      " -Matrix with path test shape:  (122, 5, 5)\n",
      "Model: \"CNN_model_v2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 3, 3, 32)          320       \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 288)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 25)                7225      \n",
      "                                                                 \n",
      " reshape_11 (Reshape)        (None, 5, 5, 1)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7545 (29.47 KB)\n",
      "Trainable params: 7545 (29.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 1s 15ms/step - loss: 0.9290 - accuracy: 0.2812 - val_loss: 0.8737 - val_accuracy: 0.3108\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.8287 - accuracy: 0.3151 - val_loss: 0.7896 - val_accuracy: 0.3269\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.3242 - val_loss: 0.7536 - val_accuracy: 0.3256\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7368 - accuracy: 0.3407 - val_loss: 0.7305 - val_accuracy: 0.3616\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.3612 - val_loss: 0.7059 - val_accuracy: 0.3738\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6895 - accuracy: 0.3811 - val_loss: 0.6803 - val_accuracy: 0.3938\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6641 - accuracy: 0.4041 - val_loss: 0.6548 - val_accuracy: 0.4125\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6404 - accuracy: 0.4185 - val_loss: 0.6326 - val_accuracy: 0.4275\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6188 - accuracy: 0.4374 - val_loss: 0.6139 - val_accuracy: 0.4479\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.4538 - val_loss: 0.5964 - val_accuracy: 0.4636\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5842 - accuracy: 0.4717 - val_loss: 0.5813 - val_accuracy: 0.4721\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.4770 - val_loss: 0.5686 - val_accuracy: 0.4793\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5560 - accuracy: 0.4883 - val_loss: 0.5554 - val_accuracy: 0.4902\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5447 - accuracy: 0.4984 - val_loss: 0.5456 - val_accuracy: 0.4967\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5346 - accuracy: 0.5072 - val_loss: 0.5367 - val_accuracy: 0.5049\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.5163 - val_loss: 0.5280 - val_accuracy: 0.5154\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.5179 - accuracy: 0.5205 - val_loss: 0.5221 - val_accuracy: 0.5200\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.5234 - val_loss: 0.5158 - val_accuracy: 0.5275\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.5323 - val_loss: 0.5102 - val_accuracy: 0.5328\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.5361 - val_loss: 0.5063 - val_accuracy: 0.5334\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4943 - accuracy: 0.5379 - val_loss: 0.5016 - val_accuracy: 0.5364\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4895 - accuracy: 0.5445 - val_loss: 0.4980 - val_accuracy: 0.5387\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.5435 - val_loss: 0.4953 - val_accuracy: 0.5423\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.5469 - val_loss: 0.4909 - val_accuracy: 0.5466\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4787 - accuracy: 0.5454 - val_loss: 0.4891 - val_accuracy: 0.5446\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.5525 - val_loss: 0.4864 - val_accuracy: 0.5498\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.5520 - val_loss: 0.4843 - val_accuracy: 0.5482\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4692 - accuracy: 0.5542 - val_loss: 0.4831 - val_accuracy: 0.5502\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4679 - accuracy: 0.5570 - val_loss: 0.4796 - val_accuracy: 0.5518\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4649 - accuracy: 0.5594 - val_loss: 0.4784 - val_accuracy: 0.5554\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4624 - accuracy: 0.5617 - val_loss: 0.4765 - val_accuracy: 0.5554\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4613 - accuracy: 0.5590 - val_loss: 0.4752 - val_accuracy: 0.5548\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4588 - accuracy: 0.5659 - val_loss: 0.4733 - val_accuracy: 0.5580\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4569 - accuracy: 0.5656 - val_loss: 0.4718 - val_accuracy: 0.5584\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4552 - accuracy: 0.5659 - val_loss: 0.4707 - val_accuracy: 0.5580\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4538 - accuracy: 0.5673 - val_loss: 0.4696 - val_accuracy: 0.5600\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.5697 - val_loss: 0.4681 - val_accuracy: 0.5639\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4510 - accuracy: 0.5688 - val_loss: 0.4660 - val_accuracy: 0.5603\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.5723 - val_loss: 0.4655 - val_accuracy: 0.5649\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.5723 - val_loss: 0.4641 - val_accuracy: 0.5626\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4463 - accuracy: 0.5728 - val_loss: 0.4632 - val_accuracy: 0.5652\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.4453 - accuracy: 0.5755 - val_loss: 0.4618 - val_accuracy: 0.5682\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.5756 - val_loss: 0.4615 - val_accuracy: 0.5662\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - 0s 8ms/step - loss: 0.4427 - accuracy: 0.5770 - val_loss: 0.4600 - val_accuracy: 0.5689\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.5765 - val_loss: 0.4590 - val_accuracy: 0.5695\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4402 - accuracy: 0.5801 - val_loss: 0.4585 - val_accuracy: 0.5708\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4390 - accuracy: 0.5788 - val_loss: 0.4575 - val_accuracy: 0.5685\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4378 - accuracy: 0.5807 - val_loss: 0.4568 - val_accuracy: 0.5741\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.5806 - val_loss: 0.4557 - val_accuracy: 0.5715\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4356 - accuracy: 0.5809 - val_loss: 0.4548 - val_accuracy: 0.5731\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4351 - accuracy: 0.5831 - val_loss: 0.4540 - val_accuracy: 0.5744\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4340 - accuracy: 0.5828 - val_loss: 0.4536 - val_accuracy: 0.5764\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.5854 - val_loss: 0.4526 - val_accuracy: 0.5777\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.5867 - val_loss: 0.4524 - val_accuracy: 0.5790\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.5863 - val_loss: 0.4510 - val_accuracy: 0.5770\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.5853 - val_loss: 0.4497 - val_accuracy: 0.5793\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.5878 - val_loss: 0.4499 - val_accuracy: 0.5800\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.5911 - val_loss: 0.4489 - val_accuracy: 0.5797\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.5885 - val_loss: 0.4482 - val_accuracy: 0.5793\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4270 - accuracy: 0.5891 - val_loss: 0.4475 - val_accuracy: 0.5797\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4260 - accuracy: 0.5909 - val_loss: 0.4466 - val_accuracy: 0.5807\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.5907 - val_loss: 0.4467 - val_accuracy: 0.5797\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.5891 - val_loss: 0.4458 - val_accuracy: 0.5813\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4244 - accuracy: 0.5910 - val_loss: 0.4453 - val_accuracy: 0.5836\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.5903 - val_loss: 0.4456 - val_accuracy: 0.5826\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4232 - accuracy: 0.5911 - val_loss: 0.4442 - val_accuracy: 0.5830\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.5934 - val_loss: 0.4436 - val_accuracy: 0.5826\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4211 - accuracy: 0.5936 - val_loss: 0.4436 - val_accuracy: 0.5833\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4205 - accuracy: 0.5928 - val_loss: 0.4429 - val_accuracy: 0.5839\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4196 - accuracy: 0.5959 - val_loss: 0.4419 - val_accuracy: 0.5849\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4191 - accuracy: 0.5958 - val_loss: 0.4417 - val_accuracy: 0.5839\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4185 - accuracy: 0.5950 - val_loss: 0.4413 - val_accuracy: 0.5852\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4183 - accuracy: 0.5952 - val_loss: 0.4409 - val_accuracy: 0.5859\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4173 - accuracy: 0.5970 - val_loss: 0.4404 - val_accuracy: 0.5859\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4168 - accuracy: 0.5965 - val_loss: 0.4394 - val_accuracy: 0.5856\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4161 - accuracy: 0.5978 - val_loss: 0.4401 - val_accuracy: 0.5872\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4154 - accuracy: 0.5979 - val_loss: 0.4387 - val_accuracy: 0.5862\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.5993 - val_loss: 0.4385 - val_accuracy: 0.5875\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.5976 - val_loss: 0.4387 - val_accuracy: 0.5869\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4141 - accuracy: 0.5984 - val_loss: 0.4377 - val_accuracy: 0.5882\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4133 - accuracy: 0.5993 - val_loss: 0.4369 - val_accuracy: 0.5885\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.5988 - val_loss: 0.4366 - val_accuracy: 0.5882\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4127 - accuracy: 0.5999 - val_loss: 0.4373 - val_accuracy: 0.5875\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4118 - accuracy: 0.6001 - val_loss: 0.4359 - val_accuracy: 0.5879\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4110 - accuracy: 0.6007 - val_loss: 0.4359 - val_accuracy: 0.5892\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.6021 - val_loss: 0.4356 - val_accuracy: 0.5882\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4100 - accuracy: 0.6016 - val_loss: 0.4348 - val_accuracy: 0.5882\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4094 - accuracy: 0.6033 - val_loss: 0.4347 - val_accuracy: 0.5898\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4091 - accuracy: 0.6018 - val_loss: 0.4338 - val_accuracy: 0.5885\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4092 - accuracy: 0.6025 - val_loss: 0.4348 - val_accuracy: 0.5908\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4083 - accuracy: 0.6032 - val_loss: 0.4327 - val_accuracy: 0.5898\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.6027 - val_loss: 0.4334 - val_accuracy: 0.5902\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4073 - accuracy: 0.6036 - val_loss: 0.4334 - val_accuracy: 0.5898\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4068 - accuracy: 0.6052 - val_loss: 0.4326 - val_accuracy: 0.5911\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4063 - accuracy: 0.6049 - val_loss: 0.4318 - val_accuracy: 0.5905\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4058 - accuracy: 0.6044 - val_loss: 0.4319 - val_accuracy: 0.5911\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4054 - accuracy: 0.6059 - val_loss: 0.4317 - val_accuracy: 0.5921\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4051 - accuracy: 0.6061 - val_loss: 0.4315 - val_accuracy: 0.5928\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4047 - accuracy: 0.6055 - val_loss: 0.4310 - val_accuracy: 0.5915\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.6060 - val_loss: 0.4313 - val_accuracy: 0.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kosma\\anaconda3\\envs\\lee_gol_cnn\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 136ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test CNN with a more Complex Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset before preprocessing:\n",
      " -Matrix shape:  (608, 5, 5)\n",
      " -Matrix after conways shape:  (608, 5, 5)\n",
      " -Matrix with path shape:  (608, 5, 5)\n",
      "\n",
      "\n",
      "Dataset after preprocessing:\n",
      " -Matrix train shape:  (486, 5, 5)\n",
      " -Matrix after conways train shape:  (486, 5, 5)\n",
      " -Matrix with path train shape:  (486, 5, 5)\n",
      " -Matrix test shape:  (122, 5, 5)\n",
      " -Matrix after conways test shape:  (122, 5, 5)\n",
      " -Matrix with path test shape:  (122, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# Global Model Parameters\n",
    "MODEL_NAME = \"CNN_model_v2\"\n",
    "EPOCHS = 100\n",
    "PATIENCE = 3\n",
    "\n",
    "# load cleaned datasets\n",
    "matrix, matrix_after_conways, matrix_with_path = np.load(\"./output/X_input_clean.npy\"), np.load(\"./output/X_after_conways_clean.npy\"), np.load(\"./output/y_target_clean.npy\")\n",
    "\n",
    "# print matrices shapes\n",
    "print(\"\\n\\nDataset before preprocessing:\")\n",
    "print(\" -Matrix shape: \", matrix.shape)\n",
    "print(\" -Matrix after conways shape: \", matrix_after_conways.shape)\n",
    "print(\" -Matrix with path shape: \", matrix_with_path.shape)\n",
    "\n",
    "\n",
    "# preprocess dataset\n",
    "(\n",
    "    matrix_train,\n",
    "    matrix_after_conways_train,\n",
    "    matrix_with_path_train,\n",
    "    matrix_test,\n",
    "    matrix_after_conways_test,\n",
    "    matrix_with_path_test,\n",
    ") = preprocess(matrix, matrix_after_conways, matrix_with_path)\n",
    "\n",
    "# print matrices shapes\n",
    "print(\"\\n\\nDataset after preprocessing:\")\n",
    "print(\" -Matrix train shape: \", matrix_train.shape)\n",
    "print(\" -Matrix after conways train shape: \", matrix_after_conways_train.shape)\n",
    "print(\" -Matrix with path train shape: \", matrix_with_path_train.shape)\n",
    "print(\" -Matrix test shape: \", matrix_test.shape)\n",
    "print(\" -Matrix after conways test shape: \", matrix_after_conways_test.shape)\n",
    "print(\" -Matrix with path test shape: \", matrix_with_path_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"CNN_model_v2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_40 (Conv2D)          (None, 5, 5, 32)          320       \n",
      "                                                                 \n",
      " batch_normalization_32 (Ba  (None, 5, 5, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 5, 5, 32)          9248      \n",
      "                                                                 \n",
      " batch_normalization_33 (Ba  (None, 5, 5, 32)          128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 5, 5, 64)          18496     \n",
      "                                                                 \n",
      " batch_normalization_34 (Ba  (None, 5, 5, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 5, 5, 64)          36928     \n",
      "                                                                 \n",
      " batch_normalization_35 (Ba  (None, 5, 5, 64)          256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 5, 5, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_36 (Ba  (None, 5, 5, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 5, 5, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_37 (Ba  (None, 5, 5, 128)         512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 3200)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 25)                80025     \n",
      "                                                                 \n",
      " reshape_12 (Reshape)        (None, 5, 5, 1)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 368249 (1.40 MB)\n",
      "Trainable params: 367353 (1.40 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - 3s 45ms/step - loss: 0.6007 - accuracy: 0.4616 - val_loss: 0.9461 - val_accuracy: 0.3161\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.4094 - accuracy: 0.6020 - val_loss: 0.9362 - val_accuracy: 0.3702\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 0s 23ms/step - loss: 0.3817 - accuracy: 0.6267 - val_loss: 0.9363 - val_accuracy: 0.3728\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 0s 24ms/step - loss: 0.3710 - accuracy: 0.6323 - val_loss: 0.9435 - val_accuracy: 0.3892\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3654 - accuracy: 0.6365 - val_loss: 0.9521 - val_accuracy: 0.4003\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3629 - accuracy: 0.6378 - val_loss: 0.9568 - val_accuracy: 0.4148\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 54ms/step - loss: 0.3623 - accuracy: 0.6383 - val_loss: 0.9619 - val_accuracy: 0.4161\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 38ms/step - loss: 0.3620 - accuracy: 0.6383 - val_loss: 0.9731 - val_accuracy: 0.4220\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 37ms/step - loss: 0.3623 - accuracy: 0.6384 - val_loss: 0.9751 - val_accuracy: 0.4325\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 0s 29ms/step - loss: 0.3621 - accuracy: 0.6382 - val_loss: 0.9746 - val_accuracy: 0.4344\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 0s 27ms/step - loss: 0.3615 - accuracy: 0.6388 - val_loss: 0.9669 - val_accuracy: 0.4331\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 0s 26ms/step - loss: 0.3613 - accuracy: 0.6389 - val_loss: 0.9600 - val_accuracy: 0.4344\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 0s 28ms/step - loss: 0.3613 - accuracy: 0.6389 - val_loss: 0.9585 - val_accuracy: 0.4361\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 0s 31ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.9508 - val_accuracy: 0.4361\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.9321 - val_accuracy: 0.4361\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 35ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.9067 - val_accuracy: 0.4377\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 42ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.8716 - val_accuracy: 0.4403\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.8421 - val_accuracy: 0.4492\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 34ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.8073 - val_accuracy: 0.4590\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 49ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.7582 - val_accuracy: 0.4744\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3612 - accuracy: 0.6389 - val_loss: 0.7090 - val_accuracy: 0.4898\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 48ms/step - loss: 0.3613 - accuracy: 0.6389 - val_loss: 0.6725 - val_accuracy: 0.5036\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 36ms/step - loss: 0.3615 - accuracy: 0.6388 - val_loss: 0.6181 - val_accuracy: 0.5243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kosma\\anaconda3\\envs\\lee_gol_cnn\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 283ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create the CNN model\n",
    "cnn = CNN(\n",
    "    matrix_after_conways_train,\n",
    "    matrix_with_path_train,\n",
    "    matrix_after_conways_test,\n",
    "    matrix_with_path_test,\n",
    ")\n",
    "\n",
    "# Build the CNN model\n",
    "cnn.build_v2()\n",
    "\n",
    "# Save the CNN model\n",
    "cnn.save()\n",
    "\n",
    "# Plot the CNN model\n",
    "cnn.plot()\n",
    "\n",
    "# Plot extra useful plots\n",
    "cnn.plot_extra()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lee_gol_cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
